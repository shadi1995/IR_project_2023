{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c992bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from linguistic_correcter import LinguisticCorrection\n",
    "from shortcuts_dictionary import ShortcutsDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95e5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexCreator:\n",
    "    shortcuts_dictionary = ShortcutsDictionary()\n",
    "    linguistic_correction = LinguisticCorrection()\n",
    "    monthDictionary = dict(jan='01', feb='02', mar='03', apr='04', may='05', jun='06', jul='07', aug='08', sep='09',\n",
    "                           oct='10', nov='11', dec='12')\n",
    "\n",
    "    def __init__(self, **args):\n",
    "        self.data = args.get('data', 'C:/Users/ASUSD/.ir_datasets/antique/train')\n",
    "        self.stopWordsFile = args.get('stopWordsFile', 'D:/IR_Project/stop words.txt')\n",
    "        self.indexFile = args.get('indexFile', 'D:/IR_Project/index1.txt')\n",
    "        self.soundexIndexFile = args.get('soundexIndexFile', 'D:/IR_Project/soundex-index.txt')\n",
    "        self.stopWords = []\n",
    "        self.index = defaultdict(list)\n",
    "        self.soundex_dic = defaultdict(set)\n",
    "        self.tfIndex = defaultdict(list)\n",
    "        self.dfIndex = defaultdict(int)\n",
    "        self.numOfDocuments = 0\n",
    "        self.porter_stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def extract_stop_words(self):\n",
    "        with open(self.stopWordsFile) as file:\n",
    "            self.stopWords = [line.strip().lower() for line in file if line.strip()]\n",
    "\n",
    "    def extract_terms(self, text):\n",
    "        text = self.shortcuts_dictionary.process_text(text)\n",
    "        text = re.sub(r'[^a-z0-9 ]', ' ', text)\n",
    "        dates = self.date_converter(text)\n",
    "        text = nltk.word_tokenize(text)\n",
    "        words = [word for word in text if word not in self.stopWords]\n",
    "        terms = []\n",
    "        for word in words:\n",
    "            term = self.porter_stemmer.stem(self.lemmatizer.lemmatize(word, 'v'))\n",
    "            terms.append(term)\n",
    "            if not re.search(r'\\W|\\d', term):\n",
    "                self.soundex_dic[self.linguistic_correction.get_soundex(term)].add(term)\n",
    "        for date in dates:\n",
    "            terms.append(date)\n",
    "        return terms\n",
    "\n",
    "    def word_to_num(self, word):\n",
    "        s = word.lower()[:3]\n",
    "        return self.monthDictionary[s]\n",
    "\n",
    "    def date_converter(self, line):\n",
    "        results = []\n",
    "        day = None\n",
    "        month = None\n",
    "        year = None\n",
    "        regex = re.search(r'([0]?\\d|[1][0-2])[/-]([0-3]?\\d)[/-]([1-2]\\d{3}|\\d{2})', line)\n",
    "        month_regex = re.search(\n",
    "            r'([0-3]?\\d)\\s*(Jan(?:uary)?(?:aury)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|June?|July?|Aug('\n",
    "            '?:ust)?|Sept?(?:ember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?(?:emeber)?).?,?\\s([1-2]\\d{3})',\n",
    "            line)\n",
    "        rev_month_regex = re.search(\n",
    "            r'(Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|June?|July?|Aug(?:ust)?|Sept?(?:ember)?|Oct('\n",
    "            '?:ober)?|Nov(?:ember)?|Dec(?:ember)?).?[-\\s]([0-3]?\\d)(?:st|nd|rd|th)?[-,\\s]\\s*([1-2]\\d{3})',\n",
    "            line)\n",
    "        no_day_regex = re.search(\n",
    "            r'(Jan(?:uary)?(?:aury)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|June?|July?|Aug(?:ust)?|Sept?('\n",
    "            '?:ember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?(?:emeber)?).?,?[\\s]([1-2]\\d{3}|\\d{2})',\n",
    "            line)\n",
    "        no_day_digits_regex = re.search(r'([0]?\\d|[1][0-2])[/\\s]([1-2]\\d{3})', line)\n",
    "        year_only_regex = re.search(r'([1-2]\\d{3})', line)\n",
    "        if regex:\n",
    "            month = regex.group(1)\n",
    "            day = regex.group(2)\n",
    "            year = regex.group(3)\n",
    "        elif month_regex:\n",
    "            day = month_regex.group(1)\n",
    "            month = self.word_to_num(month_regex.group(2))\n",
    "            year = month_regex.group(3)\n",
    "        elif rev_month_regex:\n",
    "            day = rev_month_regex.group(2)\n",
    "            month = self.word_to_num(rev_month_regex.group(1))\n",
    "            year = rev_month_regex.group(3)\n",
    "        elif no_day_regex:\n",
    "            month = self.word_to_num(no_day_regex.group(1))\n",
    "            year = no_day_regex.group(2)\n",
    "        elif no_day_digits_regex:\n",
    "            month = no_day_digits_regex.group(1)\n",
    "            year = no_day_digits_regex.group(2)\n",
    "        elif year_only_regex:\n",
    "            year = year_only_regex.group(0)\n",
    "        if day or month or year:\n",
    "            year = year if year else '1900'\n",
    "            month = month.zfill(2) if month else '01'\n",
    "            day = day.zfill(2) if day else '01'\n",
    "            if day == '00':\n",
    "                day = '01'\n",
    "            if len(year) == 2:\n",
    "                year = '19' + year\n",
    "            results.append(year + month + day)\n",
    "        return results\n",
    "\n",
    "    def process_query(self, query):\n",
    "        terms = self.extract_terms(query)\n",
    "        print(terms)\n",
    "        if not len(terms):\n",
    "            return 'Not found'\n",
    "\n",
    "        union = set()\n",
    "        for term in terms:\n",
    "            if not self.index.get(term, None):\n",
    "                continue\n",
    "            term_documents = self.index[term]\n",
    "            documents_names = {term_document[0] for term_document in term_documents}\n",
    "            union |= documents_names\n",
    "\n",
    "        return self.rank_documents(terms, list(union))\n",
    "\n",
    "    def parse_corpus(self):#parse_corpus\n",
    "        files_list = os.listdir(self.data)\n",
    "        for file in files_list:\n",
    "            yield self.parse_document(os.path.join(self.data, file))\n",
    "\n",
    "    def parse_document(self, document_file):\n",
    "        with open(document_file) as file:\n",
    "            lines = '\\n'.join(file.readlines())\n",
    "        document_name = Path(document_file).stem\n",
    "        return {'name': document_name, 'terms': self.extract_terms(lines)} if lines else {}\n",
    "\n",
    "    def create_index(self):\n",
    "        self.extract_stop_words()\n",
    "        for document in self.parse_corpus():#parse_corpus\n",
    "            if document:\n",
    "                self.numOfDocuments += 1\n",
    "                document_name = document['name']\n",
    "                terms = document['terms']\n",
    "                document_index = defaultdict(lambda: [document_name, []])\n",
    "                for position, term in enumerate(terms):\n",
    "                    document_index[term][1].append(position)\n",
    "\n",
    "                norm = math.sqrt(\n",
    "                    sum([len(positions_vector) ** 2 for term, (document_name, positions_vector) in\n",
    "                         document_index.items()]))\n",
    "\n",
    "                for term, (document_name, positions_vector) in document_index.items():\n",
    "                    self.tfIndex[term].append('%.5f' % (len(positions_vector) / norm))\n",
    "                    self.dfIndex[term] += 1\n",
    "\n",
    "                for term, positions_vector in document_index.items():\n",
    "                    self.index[term].append(positions_vector)\n",
    "        self.write_index()\n",
    "\n",
    "    def write_index(self):\n",
    "        with open(self.indexFile, 'w') as file:\n",
    "            print(self.numOfDocuments, file=file)\n",
    "            for term in self.index.keys():\n",
    "                term_documents = []\n",
    "                for document_term_index in self.index[term]:\n",
    "                    document_name = document_term_index[0]\n",
    "                    positions_vector = document_term_index[1]\n",
    "                    term_documents.append(':'.join([str(document_name), ','.join(map(str, positions_vector))]))\n",
    "\n",
    "                term_documents_positions = ';'.join(term_documents)\n",
    "                documents_tf = ','.join(map(str, self.tfIndex[term]))\n",
    "                term_idf = '%.5f' % (self.numOfDocuments / self.dfIndex[term])\n",
    "                print('|'.join((term, term_documents_positions, documents_tf, term_idf)), file=file)\n",
    "\n",
    "        with open(self.soundexIndexFile, 'w') as file:\n",
    "            print('\\n'.join([code + ':' + ','.join(group) for code, group in self.soundex_dic.items()]), file=file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147ed62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    IndexCreator().create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2308ea1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1b25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
